{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from matplotlib.backends.backend_qt5agg import FigureCanvasQTAgg\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from matplotlib.figure import Figure\n",
    "from PyQt5.QtWidgets import  QApplication, QMainWindow, QShortcut, QFileDialog , QSplitter , QFrame , QSlider\n",
    "from scipy.signal import spectrogram\n",
    "from scipy.signal import resample\n",
    "import sys\n",
    "from PyQt5.QtGui import QIcon, QKeySequence\n",
    "from mainwindow import Ui_MainWindow  \n",
    "from pyqtgraph import PlotWidget, ROI\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile\n",
    "import pyqtgraph as pg\n",
    "from scipy.fftpack import rfft, rfftfreq, irfft , fft , fftfreq\n",
    "from PyQt5.QtCore import pyqtSlot\n",
    "import sounddevice as sd\n",
    "import librosa\n",
    "import os\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openTheDoor sara\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"C:/Users/Sara/Desktop/sara_voice_code_access/voices\"\n",
    "files = os.listdir(folder_path)\n",
    "\n",
    "df = pd.DataFrame(columns = ['max_pitch', 'avg_pitch', 'variance_pitch', 'harmonic',\n",
    "       'harmonic_variance', 'percussive', 'percussive_variance', 'Chroma_cens',\n",
    "       'Chroma_cens_var', 'chroma_cqt_mean', 'chroma_cqt_variance',\n",
    "       'chroma_stft_mean', 'chroma_stft_var', 'mfcc_delta_mean',\n",
    "       'mfcc_delta_variance', 'Mfccs', 'Mfccs_variance', 'Contrast',\n",
    "       'Contrast_var', 'poly_features_mean', 'poly_features_variance',\n",
    "       'Rolloff', 'Rolloff_var', 'Zrate', 'Zrate_var', 'Cent', 'Cent_var',\n",
    "       'tonnetz_mean', 'tonnetz_var', 'spec_bw_mean', 'spec_bw_var',\n",
    "       'rmse_mean', 'rmse_var', 'melspec_mean', 'melspec_var', 'max_lpc',\n",
    "       'mean_lpc', 'var_lpc' , 'user' , 'sentense'])\n",
    "l = 0\n",
    "for file in files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    samples , sr = librosa.load(file_path)\n",
    "    # print(file_path)\n",
    "    S = np.abs(librosa.stft(samples))\n",
    "    pitches,magnitudes = librosa.core.piptrack(y = samples ,sr = sr)\n",
    "    \n",
    "    max_pitch = np.max(pitches)\n",
    "    avg_pitch = np.mean(pitches)\n",
    "    variance_pitch = np.var(pitches)\n",
    "                    \n",
    "    y_harmonic, y_percussive = librosa.effects.hpss(samples)\n",
    "    harmonic = np.mean(y_harmonic)\n",
    "    harmonic_variance = np.var(y_harmonic)\n",
    "    percussive = np.mean(y_percussive)\n",
    "    percussive_variance = np.var(y_percussive)\n",
    "                    \n",
    "    chroma=librosa.feature.chroma_cens(y=y_harmonic, sr=sr)\n",
    "    Chroma_cens = np.mean(chroma)\n",
    "    Chroma_cens_var = np.var(chroma)\n",
    "    chroma_stft =librosa.feature.chroma_stft(y=y_harmonic, sr=sr)\n",
    "    chroma_stft_mean = np.mean(chroma_stft)\n",
    "    chroma_stft_var = np.var(chroma_stft)\n",
    "                    \n",
    "    chroma_cqt =librosa.feature.chroma_cqt(y=y_harmonic, sr=sr)\n",
    "    chroma_cqt_mean = np.mean(chroma_cqt)\n",
    "    chroma_cqt_variance = np.var(chroma_cqt)\n",
    "                    \n",
    "    poly_features = librosa.feature.poly_features(S=S, sr=sr)\n",
    "    poly_features_mean = np.mean(poly_features)\n",
    "    poly_features_variance = np.var(poly_features)\n",
    "                    \n",
    "    mfccs = librosa.feature.mfcc(y=y_harmonic, sr=sr)\n",
    "    Mfccs = np.mean(mfccs)\n",
    "    \n",
    "    Mfccs_variance = np.var(mfccs)\n",
    "    delta = librosa.feature.delta(mfccs)\n",
    "    mfcc_delta_mean = np.mean(delta)\n",
    "    mfcc_delta_variance = np.var(delta)\n",
    "                    \n",
    "    melspectrogram = librosa.feature.melspectrogram(y=samples, sr=sr)\n",
    "    melspec_mean = np.mean(melspectrogram)\n",
    "    melspec_var = np.var(melspectrogram)\n",
    "                    \n",
    "    contrast=librosa.feature.spectral_contrast(y=y_harmonic,sr=sr)\n",
    "    Contrast = np.mean(contrast)\n",
    "    Contrast_var = np.var(contrast)\n",
    "                    \n",
    "    rolloff = librosa.feature.spectral_rolloff(y=samples, sr=sr)      \n",
    "    Rolloff = np.mean(rolloff)\n",
    "    Rolloff_var = np.var(rolloff)\n",
    "                    \n",
    "    zrate=librosa.feature.zero_crossing_rate(y_harmonic)\n",
    "    Zrate = np.mean(zrate)\n",
    "    Zrate_var = np.var(zrate)\n",
    "                    \n",
    "    cent = librosa.feature.spectral_centroid(y=samples, sr=sr)\n",
    "    Cent = np.mean(cent)\n",
    "    Cent_var = np.var(cent)\n",
    "                    \n",
    "    tonnetz = librosa.feature.tonnetz(y=samples, sr=sr)\n",
    "    tonnetz_mean = np.mean(tonnetz)\n",
    "    tonnetz_var = np.var(tonnetz)\n",
    "                    \n",
    "    spec_bw = librosa.feature.spectral_bandwidth(y=samples, sr=sr)\n",
    "    spec_bw_mean = np.mean(spec_bw)\n",
    "    spec_bw_var = np.var(spec_bw)\n",
    "                                         \n",
    "    rmse=librosa.feature.rms(y=samples)[0]\n",
    "    rmse_mean = np.mean(rmse)\n",
    "    rmse_var = np.var(rmse)\n",
    "                                         \n",
    "    melspectrogram = librosa.feature.melspectrogram(y=samples, sr=sr)\n",
    "    melspec_mean = np.mean(melspectrogram)\n",
    "    melspec_var = np.var(melspectrogram)\n",
    "    \n",
    "    lpc=librosa.lpc(samples, order=16)\n",
    "    max_lpc=np.max(lpc)\n",
    "    mean_lpc=np.mean(lpc)\n",
    "    var_lpc=np.var(lpc)\n",
    "    \n",
    "    target_user , target_sentense = os.path.splitext(file)[0].split('-')\n",
    "    print(target_sentense , target_user)\n",
    "    \n",
    "    data = list([max_pitch, avg_pitch,variance_pitch,harmonic,harmonic_variance,percussive, percussive_variance, Chroma_cens,Chroma_cens_var, chroma_cqt_mean, chroma_cqt_variance,chroma_stft_mean, chroma_stft_var, mfcc_delta_mean,mfcc_delta_variance, Mfccs, Mfccs_variance, Contrast,Contrast_var, poly_features_mean, poly_features_variance,Rolloff, Rolloff_var, Zrate, Zrate_var, Cent, Cent_var,tonnetz_mean,tonnetz_var,spec_bw_mean,spec_bw_var,rmse_mean, rmse_var, melspec_mean, melspec_var, max_lpc,mean_lpc,var_lpc , target_user , target_sentense])\n",
    "    df.loc[l] = data\n",
    "    l+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Team_features.csv\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   max_lpc  mean_lpc   var_lpc  user     sentense\n",
      "0      1.0  0.001005  0.344704  sara  openTheDoor\n"
     ]
    }
   ],
   "source": [
    "df_from_csv = pd.read_csv(\"Team_features.csv\")\n",
    "last_three_columns = df_from_csv.iloc[:, -5:]\n",
    "print(last_three_columns.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_pitch</th>\n",
       "      <th>avg_pitch</th>\n",
       "      <th>variance_pitch</th>\n",
       "      <th>harmonic</th>\n",
       "      <th>harmonic_variance</th>\n",
       "      <th>percussive</th>\n",
       "      <th>percussive_variance</th>\n",
       "      <th>Chroma_cens</th>\n",
       "      <th>Chroma_cens_var</th>\n",
       "      <th>chroma_cqt_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>spec_bw_var</th>\n",
       "      <th>rmse_mean</th>\n",
       "      <th>rmse_var</th>\n",
       "      <th>melspec_mean</th>\n",
       "      <th>melspec_var</th>\n",
       "      <th>max_lpc</th>\n",
       "      <th>mean_lpc</th>\n",
       "      <th>var_lpc</th>\n",
       "      <th>user</th>\n",
       "      <th>sentense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3808.014648</td>\n",
       "      <td>16.288244</td>\n",
       "      <td>25154.392578</td>\n",
       "      <td>-4.428989e-07</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>0.251823</td>\n",
       "      <td>0.019919</td>\n",
       "      <td>0.484787</td>\n",
       "      <td>...</td>\n",
       "      <td>277005.077189</td>\n",
       "      <td>0.017356</td>\n",
       "      <td>0.001398</td>\n",
       "      <td>0.404011</td>\n",
       "      <td>37.366776</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>0.344704</td>\n",
       "      <td>sara</td>\n",
       "      <td>openTheDoor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     max_pitch  avg_pitch  variance_pitch      harmonic  harmonic_variance  \\\n",
       "0  3808.014648  16.288244    25154.392578 -4.428989e-07           0.000545   \n",
       "\n",
       "   percussive  percussive_variance  Chroma_cens  Chroma_cens_var  \\\n",
       "0   -0.000002             0.000676     0.251823         0.019919   \n",
       "\n",
       "   chroma_cqt_mean  ...    spec_bw_var  rmse_mean  rmse_var  melspec_mean  \\\n",
       "0         0.484787  ...  277005.077189   0.017356  0.001398      0.404011   \n",
       "\n",
       "   melspec_var  max_lpc  mean_lpc   var_lpc  user     sentense  \n",
       "0    37.366776      1.0  0.001005  0.344704  sara  openTheDoor  \n",
       "\n",
       "[1 rows x 40 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     max_pitch  avg_pitch  variance_pitch      harmonic  harmonic_variance  \\\n",
      "0  3808.014648  16.288244    25154.392578 -4.428989e-07           0.000545   \n",
      "\n",
      "   percussive  percussive_variance  Chroma_cens  Chroma_cens_var  \\\n",
      "0   -0.000002             0.000676     0.251823         0.019919   \n",
      "\n",
      "   chroma_cqt_mean  ...  tonnetz_var  spec_bw_mean    spec_bw_var  rmse_mean  \\\n",
      "0         0.484787  ...     0.005325   2265.635973  277005.077189   0.017356   \n",
      "\n",
      "   rmse_var  melspec_mean  melspec_var  max_lpc  mean_lpc   var_lpc  \n",
      "0  0.001398      0.404011    37.366776      1.0  0.001005  0.344704  \n",
      "\n",
      "[1 rows x 38 columns]\n",
      "   user\n",
      "0  sara\n",
      "      sentense\n",
      "0  openTheDoor\n"
     ]
    }
   ],
   "source": [
    "features = df.drop(['user' , 'sentense'] , axis=1)\n",
    "target_sentense = pd.DataFrame(df[\"user\"]) \n",
    "target_user = pd.DataFrame(df[\"sentense\"]) \n",
    "print(features.head())\n",
    "print(target_sentense.head())\n",
    "print(target_user.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=1, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[88], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train_sentense, X_test_sentense, y_train_sentense, y_test_sentense \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_sentense\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Split the data into training and testing sets for user prediction\u001b[39;00m\n\u001b[0;32m      4\u001b[0m X_train_user, X_test_user, y_train_user, y_test_user \u001b[38;5;241m=\u001b[39m train_test_split(features, target_user, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Sara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2562\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2559\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[0;32m   2561\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m-> 2562\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[0;32m   2564\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m   2567\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Sara\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2236\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2233\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[0;32m   2235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2236\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2237\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2238\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2239\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[0;32m   2240\u001b[0m     )\n\u001b[0;32m   2242\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=1, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "X_train_sentense, X_test_sentense, y_train_sentense, y_test_sentense = train_test_split(features, target_sentense, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the data into training and testing sets for user prediction\n",
    "X_train_user, X_test_user, y_train_user, y_test_user = train_test_split(features, target_user, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Random Forest models for sentense and user prediction\n",
    "rf_sentense = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_sentense.fit(X_train_sentense, y_train_sentense)\n",
    "\n",
    "rf_user = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_user.fit(X_train_user, y_train_user)\n",
    "\n",
    "# Make predictions on the test set for sentense and user\n",
    "predictions_sentense = rf_sentense.predict(X_test_sentense)\n",
    "predictions_user = rf_user.predict(X_test_user)\n",
    "\n",
    "# Evaluate the accuracy of the models\n",
    "accuracy_sentense = accuracy_score(y_test_sentense, predictions_sentense)\n",
    "accuracy_user = accuracy_score(y_test_user, predictions_user)\n",
    "print(accuracy_sentense)\n",
    "print(accuracy_user)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
